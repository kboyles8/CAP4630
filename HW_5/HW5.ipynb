{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ET6NursKcce5",
        "PZs8eGz7GQk1",
        "V1lLieWJAF9e",
        "E_Wel3UgKb7R",
        "bEhlP0_7Kkkn",
        "SyqSBz2bKoPe",
        "q3mg8KF-M_UW",
        "zWqJRUNJNV9z",
        "648GUFbqAIfo",
        "d2aDx0gKKsZ4",
        "Ao5Jkf_xKvjs",
        "h-FAvYHWRmbN",
        "wC7bRk8cKxcl",
        "KcDMy52xK0vw",
        "Hd9W0dA3Rul4",
        "afbykKn3dl6w",
        "PAH_gabedtUH",
        "xTgpBeS2eBeB",
        "Xm0I0sVVAJ0V",
        "P1_Wnjp5kSRW",
        "ERvLA5hElQAx",
        "Eci5aPuylUCV",
        "WTLVX8IYlY2F",
        "XJbSW-k7pZJ9",
        "_56bv6K3pa50",
        "Mh6i_Fakl2jW",
        "MKs-MCmul5Zs",
        "DXGTy0X6l9YL",
        "rsdJ-tBSl-1j",
        "IChYvdOUuuMX",
        "-DX_WF7qALMG",
        "BE9a_oCrzfmL",
        "x8nmI8g2ziaP",
        "lRKB5ASr0Bta",
        "ZHG36_Zo0W-m",
        "uRbnz2GMAMTV",
        "rt8VW21TBya-",
        "trfU-IscCLoq",
        "Jx6XCBFSCkcn",
        "TB7eCEQfEgGg",
        "0-HC7q27EihC",
        "lB3myMCiFc65"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOav4SwV/xTmB/chLn/bG4E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kboyles8/CAP4630/blob/master/HW_5/HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI9k0eT2_jM_",
        "colab_type": "text"
      },
      "source": [
        "# Summary of Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDneFHfR_ni7",
        "colab_type": "text"
      },
      "source": [
        "In this assignment, a summary of the concepts, methods, and algorithms I have learned in this class is provided. Code examples are given where appropriate to reinforce the concepts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET6NursKcce5",
        "colab_type": "text"
      },
      "source": [
        "## Global Imports and Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaYyfVOHc-Bz",
        "colab_type": "text"
      },
      "source": [
        "Commonly used packages are imported, and initial setup is performed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QICZDyISce68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Fix seed for consistent results\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZs8eGz7GQk1",
        "colab_type": "text"
      },
      "source": [
        "### Data Gathering and Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj2lbXQMdGSW",
        "colab_type": "text"
      },
      "source": [
        "This method is used later to generate random data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssglOBv1-3Na",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_data(w, b, mu, sigma, m):\n",
        "    num_train = (int)(m * 0.8)\n",
        "\n",
        "    C = np.random.randint(0, 2, size=(m, 1))\n",
        "    X_1 = np.random.uniform(size=(m, 1))\n",
        "    N = np.random.normal(mu, sigma, size=(m, 1))\n",
        "\n",
        "    X_2 = w * X_1 + b + (-1)**C * N\n",
        "\n",
        "    data = np.concatenate((X_1, X_2), axis=1)\n",
        "    labels = C\n",
        "\n",
        "    return ((data[:num_train], labels[:num_train]), (data[num_train:], labels[num_train:]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NccnetBA2-UI",
        "colab_type": "text"
      },
      "source": [
        "This sets up the CIFAR data for use in the Keras model sections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PSYHRBv29rH",
        "colab_type": "code",
        "outputId": "dfac844c-40bd-4e64-86c6-d8bf9818a2e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "(cifar_train_images_original, cifar_train_labels_original), (cifar_test_images_original, cifar_test_labels_original) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "cifar_train_images_shaped = cifar_train_images_original.reshape((50000, 32, 32, 3))\n",
        "cifar_train_images_shaped = cifar_train_images_shaped.astype('float32') / 255\n",
        "cifar_test_images = cifar_test_images_original.reshape((10000, 32, 32, 3))\n",
        "cifar_test_images = cifar_test_images.astype('float32') / 255\n",
        "\n",
        "cifar_train_images = cifar_train_images_shaped[:45000]\n",
        "cifar_validation_images = cifar_train_images_shaped[45000:]  # Use the last 5000 images as validation data\n",
        "\n",
        "# categorically encode the labels\n",
        "cifar_train_labels_cat = tf.keras.utils.to_categorical(cifar_train_labels_original)\n",
        "cifar_train_labels = cifar_train_labels_cat[:45000]\n",
        "cifar_validation_labels = cifar_train_labels_cat[45000:]\n",
        "cifar_test_labels = tf.keras.utils.to_categorical(cifar_test_labels_original)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1lLieWJAF9e",
        "colab_type": "text"
      },
      "source": [
        "## General Concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_Wel3UgKb7R",
        "colab_type": "text"
      },
      "source": [
        "### Artificial Intelligence (AI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az3L1KE8A9KB",
        "colab_type": "text"
      },
      "source": [
        "Artificial Intelligence (AI) is a broad category that represents intelligent programs which can immitate human behavior. This includes topics such as speech recognition, image classification, and understanding human language. This class focussed on the classification of images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEhlP0_7Kkkn",
        "colab_type": "text"
      },
      "source": [
        "### Symbolic AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elh183NRKm5N",
        "colab_type": "text"
      },
      "source": [
        "Symbolic AI is a subset of AI in which rules are established that determine the behavior of the program. Given an input and a set of rules, the program produces some output. Due to the complicated nature of many tasks such as image classification, it is infeasible to develop rules for the task, making this type of AI somewhat limited."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyqSBz2bKoPe",
        "colab_type": "text"
      },
      "source": [
        "### Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqHLBzK3Koj3",
        "colab_type": "text"
      },
      "source": [
        "Machine Learning is a subset of AI which involves programs which can \"learn\" from data they are exposed to. In this form, input and expected output are given to the program, and a set of rules are produced. These rules can be used later for predicting output for arbitrary input. While the process for setting up models can be complex, this process allows for far more complex behaviors to be modeled without the need to program all rules manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3mg8KF-M_UW",
        "colab_type": "text"
      },
      "source": [
        "### Supervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk8Gpva9NBSw",
        "colab_type": "text"
      },
      "source": [
        "In Supervised learning, input data to a model have labels attached which identify them. These labels are used when creating rules and classifications during learning. Typically, the model is trained to predict the label of data based on the previously seen labeled data. This form of learning is what the class focused on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWqJRUNJNV9z",
        "colab_type": "text"
      },
      "source": [
        "### Unsupervised Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12mt0geCNYkf",
        "colab_type": "text"
      },
      "source": [
        "In Unsupervised learning, input data has no attached labels. The model does not know how any of the data is related and must create its own rules and categories for the data. These rules can be used later to group unknown input data into the generated categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "648GUFbqAIfo",
        "colab_type": "text"
      },
      "source": [
        "## Basic Concepts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2aDx0gKKsZ4",
        "colab_type": "text"
      },
      "source": [
        "### Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL_sJmf-OVoP",
        "colab_type": "text"
      },
      "source": [
        "Linear Regression is a formula for predicting continuous values. The equation for the predictions of the model is of the form $\\hat{y} = b + w_1x_1 + w_2x_2 + \\dots + w_nx_n$, where $\\hat{y}$ is the predicted label, $b$ is the bias, $X = \\begin{bmatrix} x_1 & x_2 & \\dots & x_n \\end{bmatrix}$ are the features, and $W = \\begin{bmatrix} w_1 & w_2 & \\dots & w_n \\end{bmatrix}$ are the weights of the features.\n",
        "\n",
        "Using matricies, the equation can be rewritten as $\\hat{y} = b + WX^T$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao5Jkf_xKvjs",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWVG3IELab_N",
        "colab_type": "text"
      },
      "source": [
        "Logistic Regression is a formula for predicting binary values. The result of the equation is represented as a percentage chance that the result is of one of the two categories. The sigmoid activation function is used to restrict the value to a range of $(0, 1)$. Below are functions for the sigmoid function, and logistic regression predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kXkx9CSbClR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform the sigmoid activation function on an input `z`\n",
        "def sigmoid(z):\n",
        "    return 1.0 / (1.0 + np.exp(np.negative(z)))\n",
        "\n",
        "# Process the input `X_b` according to the weights `W_b`\n",
        "def process_input(X_b, W_b):\n",
        "    # Apply weights and bias\n",
        "    z = W_b.T.dot(X_b)\n",
        "\n",
        "    # Perform sigmoid activation function\n",
        "    return sigmoid(z)\n",
        "\n",
        "# Make a prediction based on the result `a`\n",
        "def predict(a):\n",
        "    return 0 if a < 0.5 else 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-FAvYHWRmbN",
        "colab_type": "text"
      },
      "source": [
        "### Error and Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6JRCLQxSzg_",
        "colab_type": "text"
      },
      "source": [
        "Loss is a measurement of how far off a model's prediction is from the true value. A loss of 0 is a perfect prediction. Loss is important as it is used to optimize the weights for a model and make better predictions.\n",
        "\n",
        "One form of loss is Squared Error. It is calculated as $L = (y - \\hat{y})^2$, where $y$ is the true label and $\\hat{y}$ is the predicted label.\n",
        "\n",
        "Mean Squared Error is a representation of Squared Error loss over a batch of predictions instead of one prediction. It is calculated as $MSE = \\frac{1}{m} \\sum_{i = 1}^{m}L^{(i)}$, where $m$ is the number of elements in the dataset.\n",
        "\n",
        "Below is code for another type of loss, binary cross-entropy. This is used with Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-g0zPBFb9gy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calcualte the binary cross-entropy loss for the prediction `a` and true label `label`\n",
        "def binary_crossentropy(a, label):\n",
        "    return -label*np.log(a) - (1 - label)*np.log(1 - a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC7bRk8cKxcl",
        "colab_type": "text"
      },
      "source": [
        "### Gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFIHRK3yVZWE",
        "colab_type": "text"
      },
      "source": [
        "A gradient is a vector which represents the direction and magnitude of steepest ascent for a function at a given point. It is used in combination with the loss function to determine which direction to move to reduce the loss. The gradeint of the loss is calculated as\n",
        "$\\nabla{}L = \\begin{bmatrix}\n",
        "\\frac{\\partial{}L}{\\partial{b}} &\n",
        "\\frac{\\partial{}L}{\\partial{w_1}} &\n",
        "\\frac{\\partial{}L}{\\partial{w_2}} &\n",
        "\\dots &\n",
        "\\frac{\\partial{}L}{\\partial{w_n}} &\n",
        "\\end{bmatrix}$\n",
        "\n",
        "Below is code to calculate binary cross-entropy loss, used in Logistic Regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVViRvS6cMQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the gradient of the binary cross-entropy loss for the prediction `a`, true label `label`, and input `X_b`\n",
        "def loss_gradient(a, label, X_b):\n",
        "    return (a - label) * X_b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcDMy52xK0vw",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwAAibGvUvJ5",
        "colab_type": "text"
      },
      "source": [
        "Gradient Descent is a process for minimizing the loss of a model by adjusting the weights. To begin, weights are set to some arbitrary value. Predictions are made on some input data, and the loss is calculated. The gradient of that loss is calculated to determine the direction of steepest increase in loss. Finally, the weights are updated as $W = W - \\alpha\\nabla{}L$, where $\\alpha$ is the learning rate. This value simply scales the effect the gradient has on the weights.\n",
        "\n",
        "There are 3 forms of Gradient Descent:\n",
        "\n",
        "- Batch: Uses all data from the training set\n",
        "- Mini-batch: Uses a subset of the data from the training set\n",
        "- Stochastic: Uses only a single element from the training set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd9W0dA3Rul4",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlLSlBe5Rv7l",
        "colab_type": "text"
      },
      "source": [
        "Training a model is simply the process of iteratively running the model against test data, making predictions, and adjusting the weights of the model to minimize the loss. Doing this can lead the model to make better predictions for future runs.\n",
        "\n",
        "An Epoch represents a cycle in which all elements of the training set are considered. Multiple epochs will go over the training data multiple times.\n",
        "\n",
        "The rate at which a model changes is called the learning rate. By lowering this value, the model will change slower. This may be helpful to avoid divergence in training. This can happen when the model changes so much that it overshoots the ideal weights and causes the gradient to be even larger next time. This can continue forever, with the model getting further and further from the ideal value.\n",
        "\n",
        "Below is code for performing Gradient Descent using Logistic Regression to train a model against some test data. More information about the training of models will be found in the section Training a Keras Model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afbykKn3dl6w",
        "colab_type": "text"
      },
      "source": [
        "#### Create Data to Use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qESktMQPcp1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set parameters\n",
        "w = 2\n",
        "b = 4\n",
        "mu = 3\n",
        "sigma = 1.5\n",
        "m = 1000\n",
        "\n",
        "# Gather train and test data\n",
        "(train_data, train_labels), (test_data, test_labels) = get_random_data(w, b, mu, sigma, m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAH_gabedtUH",
        "colab_type": "text"
      },
      "source": [
        "#### Define Test Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56MljNxbd3iM",
        "colab_type": "text"
      },
      "source": [
        "This function will test the logistic regression model against the test data, and return the loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHe0F2Qld_it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform a test of the model using the test data and labels, with weights `W_b`\n",
        "def test_model(test_data, test_labels, W_b):\n",
        "    correct_predictions = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    for i_data in range(len(test_data)):\n",
        "        # Process the input\n",
        "        X_b = np.concatenate(([1], test_data[i_data]))\n",
        "        a = process_input(X_b, W_b)\n",
        "\n",
        "        # Make a prediction\n",
        "        p = predict(a)\n",
        "        if p == test_labels[i_data]:\n",
        "            correct_predictions += 1\n",
        "        \n",
        "        # Determine loss\n",
        "        total_loss += binary_crossentropy(a, test_labels[i_data])\n",
        "\n",
        "    # Return a summary\n",
        "    return (total_loss[0] / len(test_data), correct_predictions / len(test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTgpBeS2eBeB",
        "colab_type": "text"
      },
      "source": [
        "#### Run the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDZSm3TXeNo_",
        "colab_type": "text"
      },
      "source": [
        "This runs the Logistic Regression model over 10 epochs, with a learning rate of 0.01, and displays the results for each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ1FA0_BeEav",
        "colab_type": "code",
        "outputId": "6b4c478a-8e93-4779-b9b7-fa120327e2f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "def logistic_regression(train_data, train_labels, test_data, test_labels, epochs, learing_rate):\n",
        "    # Randomize the initial weights\n",
        "    W_b = np.random.random_sample((3, ))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Only perform stochastic gradient descent\n",
        "        for i_data in range(len(train_data)):\n",
        "            # Process the input\n",
        "            X_b = np.concatenate(([1], train_data[i_data]))\n",
        "            a = process_input(X_b, W_b)\n",
        "\n",
        "            # Determine the gradient of the loss\n",
        "            Lg_b = loss_gradient(a, train_labels[i_data], X_b)\n",
        "\n",
        "            # Apply the gradient to the weights\n",
        "            W_b -= Lg_b * learning_rate\n",
        "        \n",
        "        # Analyze the loss and accuracy for each epoch\n",
        "        loss, accuracy = test_model(test_data, test_labels, W_b)\n",
        "        print(f'Epoch {epoch+1}/{epochs} - val_loss: {loss} - val_accuracy: {accuracy}')\n",
        "    \n",
        "    # Return the trained weights\n",
        "    return W_b\n",
        "\n",
        "epochs = 10\n",
        "learning_rate = 0.01\n",
        "\n",
        "W_b = logistic_regression(train_data, train_labels, test_data, test_labels, epochs, learning_rate)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - val_loss: 0.2852680517706631 - val_accuracy: 0.91\n",
            "Epoch 2/10 - val_loss: 0.21490160669396283 - val_accuracy: 0.94\n",
            "Epoch 3/10 - val_loss: 0.17917091160280488 - val_accuracy: 0.96\n",
            "Epoch 4/10 - val_loss: 0.15762120145374078 - val_accuracy: 0.96\n",
            "Epoch 5/10 - val_loss: 0.14321953921728175 - val_accuracy: 0.97\n",
            "Epoch 6/10 - val_loss: 0.13292257130692947 - val_accuracy: 0.97\n",
            "Epoch 7/10 - val_loss: 0.1252011842969439 - val_accuracy: 0.975\n",
            "Epoch 8/10 - val_loss: 0.11920285429900232 - val_accuracy: 0.975\n",
            "Epoch 9/10 - val_loss: 0.11441447294496017 - val_accuracy: 0.98\n",
            "Epoch 10/10 - val_loss: 0.11050855719863474 - val_accuracy: 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm0I0sVVAJ0V",
        "colab_type": "text"
      },
      "source": [
        "## Building a Keras Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddcV9ogzleAp",
        "colab_type": "text"
      },
      "source": [
        "The primary type of model focused on in this class is convolutional neural networks. These networks were used for classification of images. In this section, information about building a Keras model is outlined, and a model for identifying CIFAR images is created."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1_Wnjp5kSRW",
        "colab_type": "text"
      },
      "source": [
        "### Types of Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qa25RnClmr4",
        "colab_type": "text"
      },
      "source": [
        "To begin, a description of each type of layer is given. These layers are combined to create the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERvLA5hElQAx",
        "colab_type": "text"
      },
      "source": [
        "#### Dense Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkIXfS2alsBu",
        "colab_type": "text"
      },
      "source": [
        "Dense layers are the typical type of layer. They use a form of Gradient Descent to adjust weights based on input to produce a set of outputs. Each output can be a different learned set of weights, leading to the identification of features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eci5aPuylUCV",
        "colab_type": "text"
      },
      "source": [
        "#### Conv2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeuoX5eOqerB",
        "colab_type": "text"
      },
      "source": [
        "Convolutional layers were used for image recognition in this class. These function by applying a kernel matrix to an input matrix, to produce an output matrix.\n",
        "\n",
        "The stride value determines how far to move the kernel with each operation. By default, it moves by 1.\n",
        "\n",
        "The process starts in the top left corner of the input array. The kernel is multiplied into a section of the input array equal to its size, and the resulting matrix is summed and placed into position (0, 0) in the output array. The kernel is then shifted right by the stride value, and the process continues until the end of the input array is reached. The kernel moves back to the left and down by the stride amount.\n",
        "\n",
        "If there is not room at the end of the array due to the stride amount, the input array can optionally be padded to allow running the final operation. If padding is not set, the last operation is skipped instead.\n",
        "\n",
        "For example, an input matrix of \n",
        "$\\begin{bmatrix}\n",
        "1 & 2 & 1 & 2 \\\\\n",
        "2 & 1 & 2 & 1 \\\\\n",
        "1 & 2 & 1 & 2 \\\\\n",
        "2 & 1 & 2 & 1\n",
        "\\end{bmatrix}$\n",
        ", and a kernel of\n",
        "$\\begin{bmatrix}\n",
        "1 & 0 \\\\\n",
        "0 & 1\n",
        "\\end{bmatrix}$\n",
        "would produce an output of\n",
        "$\\begin{bmatrix}\n",
        "2 & 4 & 2 \\\\\n",
        "4 & 2 & 4 \\\\\n",
        "2 & 4 & 2\n",
        "\\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTLVX8IYlY2F",
        "colab_type": "text"
      },
      "source": [
        "#### Maxpooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcJkz5Qgr9bC",
        "colab_type": "text"
      },
      "source": [
        "MaxPooling is another layer used with image recognition in the class. Typically, they were used after a Conv2D layer. These layers take an input matrix and a window size `s`, and produce an output matrix. The stride is assumed to be the window size, but can be different.\n",
        "\n",
        "The process starts in the top left corner of the input array. The maximum value within an `s` by `s` region is found and placed into the output array at (0, 0). The window moves right by `s`, and the process repeats until the window cannot fit into the input array. The window then moves down `s` and back to the left of the input array. This continues until the window falls off the bottom of the input array.\n",
        "\n",
        "If the window only partially fits into the input array, the array can optionally be padded to allow running the final operation. This will pad with the same values at the end of the array, effectively treating the empty spots as $-\\infty$. If padding is not set, the last operation is skipped instead.\n",
        "\n",
        "For example, an input matrix of\n",
        "$\\begin{bmatrix}\n",
        "1 & 2 & 1 & 2 \\\\\n",
        "2 & 4 & 2 & 1 \\\\\n",
        "1 & 2 & 4 & 2 \\\\\n",
        "2 & 1 & 2 & 1\n",
        "\\end{bmatrix}$\n",
        "with a window size of `2` would produce an output of\n",
        "$\\begin{bmatrix}\n",
        "4 & 2 \\\\\n",
        "2 & 4\n",
        "\\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJbSW-k7pZJ9",
        "colab_type": "text"
      },
      "source": [
        "#### Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmy2_oJutsGY",
        "colab_type": "text"
      },
      "source": [
        "The Flatten layer takes an input of arbitrary shape and flattens it into a one-dimensional array. For example, an input matrix of size `(16, 8)` would become an array of size `(128,)`.\n",
        "\n",
        "This was used specifically to transition from a series of Conv2D layers into Dense layers. Conv2D layers work on 2D arrays, while Dense layers can only handle 1D arrays."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_56bv6K3pa50",
        "colab_type": "text"
      },
      "source": [
        "#### Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbMsOKK7uO5U",
        "colab_type": "text"
      },
      "source": [
        "Dropout layers work by randomly setting a percentage of the input nodes to `0`, removing them from consideration in future layers. This is useful to help prevent overfitting by adding more noise to the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh6i_Fakl2jW",
        "colab_type": "text"
      },
      "source": [
        "### Activation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qqw6xIEm1tC",
        "colab_type": "text"
      },
      "source": [
        "Several activation functions were used in this class, which are outlined below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKs-MCmul5Zs",
        "colab_type": "text"
      },
      "source": [
        "#### Sigmoid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aY2ei_kmEVE",
        "colab_type": "text"
      },
      "source": [
        "The Sigmoid activation function is used to clamp values to a range of $(0, 1)$, which is useful for binary classifications. A code example is given in the section on Logistic Regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXGTy0X6l9YL",
        "colab_type": "text"
      },
      "source": [
        "#### SoftMax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1VRPrE-oO0U",
        "colab_type": "text"
      },
      "source": [
        "SoftMax was used for multi-class single-label classification. That is, given a set of categories, each input is predicted to be in one of the categories. The SoftMax activation function generates a probability from $(0, 1)$ for each category class. Using these probabilities, it can be determined what the most likely label is for an input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsdJ-tBSl-1j",
        "colab_type": "text"
      },
      "source": [
        "#### Rectified Linear Unit (ReLU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElCWah69mbw4",
        "colab_type": "text"
      },
      "source": [
        "ReLU is used to restrict the output of a layer to non-negative numbers. The formula is $ReLU(x) = max(0, x)$. I commonly saw this activation function used for hidden layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IChYvdOUuuMX",
        "colab_type": "text"
      },
      "source": [
        "### Creating a Convolutional Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnsvRCw5uxNm",
        "colab_type": "text"
      },
      "source": [
        "The process for creating a model with Keras follows some common patterns and guidelines, but can require trial and error in many cases. In the code below, a simple convolutional model is created to identify images from the CIFAR dataset.\n",
        "\n",
        "3 Conv2D layers are used to generate features based on the input images. Between the convolutions, a MaxPooling2D layer is used to extract only the most important of these features. A Dropout layer is used to reduce overfitting. The data is then flattened and fed into a hidden Dense layer to generate more features. Finally, the data is fed into a Dense layer with SoftMax activation to make a prediction on which category is represented by the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4drYDtc4vAZx",
        "colab_type": "code",
        "outputId": "eeeb7c11-4349-4f9b-97cb-57c6eccf8584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "conv_model = tf.keras.models.Sequential(layers=(\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "))\n",
        "\n",
        "conv_model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                65600     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 122,570\n",
            "Trainable params: 122,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DX_WF7qALMG",
        "colab_type": "text"
      },
      "source": [
        "## Compiling a Keras Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqAJIri5xBCl",
        "colab_type": "text"
      },
      "source": [
        "Once a model has been built, the model must be compiled. To do so, some additional properties must be defined. These properties are outlined in this section, and the model from before is compiled."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE9a_oCrzfmL",
        "colab_type": "text"
      },
      "source": [
        "#### Choose an Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoAAQffZzhgL",
        "colab_type": "text"
      },
      "source": [
        "Fisrt, an optimizer is selected. This defines the formula used to optimize the weights of each layer for every batch. Two of these are listed below.\n",
        "\n",
        "- SGD (Stochastic Gradient Descent): Perform standard gradient descent\n",
        "- RMSprop: Keeps a running average of the square of the gradient. This gives the optimizer some momentum, which smoothes optimization and prevents outliers from having as large of an effect.\n",
        "\n",
        "The optimizer also takes a learning rate, which affects how fast the model changes. This rate is important as a learning rate that is too large can cause overshooting, divergence, and other issues with training. A value too small can also be a problem, as it will make the training process take a very long time.\n",
        "\n",
        "For this model, RMSprop was chosen with a learning rate of 0.001.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8nmI8g2ziaP",
        "colab_type": "text"
      },
      "source": [
        "#### Choose a Loss Type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oazh8LUXzlZU",
        "colab_type": "text"
      },
      "source": [
        "Different types of loss have different uses. In this class, I learned the general guideline to pick the loss type based on the type of classification.\n",
        "\n",
        "- Binary Classification: If there are only 2 classes, use `binary_crossentropy`\n",
        "- Multi-class single-label: If there are more than 2 classes, use `categorical_crossentropy`\n",
        "\n",
        "Since there are 10 classes, `categorical_crossentropy` is used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRKB5ASr0Bta",
        "colab_type": "text"
      },
      "source": [
        "#### Choose Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXLUOEqj0DlG",
        "colab_type": "text"
      },
      "source": [
        "Metrics do not affect the training of the model. They are used only by the observer to judge the performance of the model. For this class, we were mainly interested in `accuracy`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHG36_Zo0W-m",
        "colab_type": "text"
      },
      "source": [
        "### Compiling the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okXxt69q0YzP",
        "colab_type": "text"
      },
      "source": [
        "Using the information above, the model is compiled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXsg1t5hxPsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "conv_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001), \n",
        "                   loss='categorical_crossentropy', \n",
        "                   metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRbnz2GMAMTV",
        "colab_type": "text"
      },
      "source": [
        "## Training a Keras Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTgS_pXW02mS",
        "colab_type": "text"
      },
      "source": [
        "Once a model is compiled, it is time to train it. \n",
        "\n",
        "In this section, the aspects of training are described in more detail, and the compiled model from before is trained to recognize MNIST digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt8VW21TBya-",
        "colab_type": "text"
      },
      "source": [
        "#### Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Goj2IVk7B0Pj",
        "colab_type": "text"
      },
      "source": [
        "Training the model is done by using a set of data called the training set. This is what the model makes predictions and optimizations on.\n",
        "\n",
        "A second set, the validation set, is used to judge the performance of the model each epoch. This gives an indication of how the training is going.\n",
        "\n",
        "A third set of data, the test set, is used to test the model after training. The reason for not reusing the validation set is to prevent bias in the results. Keeping the data separated prevents decision making based on a known set of data, and helps to train a model that works for the general problem instead of a specific set of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trfU-IscCLoq",
        "colab_type": "text"
      },
      "source": [
        "#### Epochs and Batch Size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9L_8qSACN8n",
        "colab_type": "text"
      },
      "source": [
        "Epochs are the number of times the model will run through all of the training data. Batch size is how many elements of the training data are considered at a time when performing optimization on the weights. Modifying these values changes the speed and behavior of training.\n",
        "\n",
        "I chose to use 10 epochs, with a batch size of 32."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx6XCBFSCkcn",
        "colab_type": "text"
      },
      "source": [
        "#### Overfitting and Underfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7LNqbTUCmKD",
        "colab_type": "text"
      },
      "source": [
        "Overfitting is a serious issue with machine learning models. This happens when the model develops rules that are too specific to the training dataset and don't generalize well. This causes a very low loss on the training data, but a high loss on unseen test data. The model cannot adapt to the new data.\n",
        "\n",
        "To avoid overfitting, the model must not train for too long on the training data. Another way of helping this is to add Dropoout layers, which create noise in the training data and help to prevent fitting too much on the training data. Another way to prevent it is to reduce the complexity of the model. This causes the model to create more general rules to fit the data, rather than many rules that are specific to the training set.\n",
        "\n",
        "Underfitting is the opposite issue. The model has high loss on both the training set and the test set. The model cannot fit to the training set or generalize to new data. To help this, the model may need to be trained for longer, have a higher learning rate, have a more complex structure, or use different techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB7eCEQfEgGg",
        "colab_type": "text"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OLmB8vMErdl",
        "colab_type": "text"
      },
      "source": [
        "The model is trained against the training dataset, and validated against the validation set to monitor progress. The model does well at categorizing both sets of data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVtq1LDf4Rek",
        "colab_type": "code",
        "outputId": "39d2715d-e598-419b-d8ad-1a8aa5d17c0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "conv_model.fit(cifar_train_images, \n",
        "               cifar_train_labels, \n",
        "               epochs=10, \n",
        "               batch_size=32,\n",
        "               validation_data=(cifar_validation_images, cifar_validation_labels))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.5727 - accuracy: 0.4305 - val_loss: 1.4389 - val_accuracy: 0.4906\n",
            "Epoch 2/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.1833 - accuracy: 0.5834 - val_loss: 1.0720 - val_accuracy: 0.6196\n",
            "Epoch 3/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 1.0223 - accuracy: 0.6387 - val_loss: 1.1585 - val_accuracy: 0.5920\n",
            "Epoch 4/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.9169 - accuracy: 0.6800 - val_loss: 1.1359 - val_accuracy: 0.6262\n",
            "Epoch 5/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.8350 - accuracy: 0.7100 - val_loss: 0.9369 - val_accuracy: 0.6852\n",
            "Epoch 6/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.7780 - accuracy: 0.7286 - val_loss: 0.9318 - val_accuracy: 0.6762\n",
            "Epoch 7/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.7238 - accuracy: 0.7473 - val_loss: 0.8710 - val_accuracy: 0.7092\n",
            "Epoch 8/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.6838 - accuracy: 0.7630 - val_loss: 0.9518 - val_accuracy: 0.6758\n",
            "Epoch 9/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.6462 - accuracy: 0.7739 - val_loss: 1.0262 - val_accuracy: 0.6854\n",
            "Epoch 10/10\n",
            "1407/1407 [==============================] - 6s 4ms/step - loss: 0.6127 - accuracy: 0.7865 - val_loss: 1.2096 - val_accuracy: 0.6606\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f76e00621d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-HC7q27EihC",
        "colab_type": "text"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pCljE4WEkXW",
        "colab_type": "text"
      },
      "source": [
        "Finaly, the model is tested against the never-used test dataset. The model has relatively high accuracy, indicating that the model was effective."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Zz8dQOa470D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "16b2cc21-69c8-46b1-dd49-6f1547a35af7"
      },
      "source": [
        "conv_model.evaluate(cifar_test_images, cifar_test_labels)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 1.2115 - accuracy: 0.6500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.211479663848877, 0.6499999761581421]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vt9BX-BAPLK",
        "colab_type": "text"
      },
      "source": [
        "## Fine-tuning a Pretrained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhZIktw7E6td",
        "colab_type": "text"
      },
      "source": [
        "To avoid the hassle of creating and training networks from scratch, pretrained models are provided. These models are well-designed and tested, and trained against very large sets of data to generalize well to many different problems. In this section, the pretrained convolutional model DenseNet121 is used to create a model to identify the CIFAR images. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB3myMCiFc65",
        "colab_type": "text"
      },
      "source": [
        "### Download the Pretrained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7wnQg7wFfsj",
        "colab_type": "text"
      },
      "source": [
        "First, the pretrained model must be downloaded and configured. The model is created with initial weights from ImageNet training. The \"top\" of the network is the final dense layers. This is left off so that a custom set of dense layers can be added. The model is set to be untrainable so that the weights will not change when adapting the added Dense layers for the CIFAR image set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXpEM79QFiCT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0118bcca-b568-462b-cb65-973f366a321f"
      },
      "source": [
        "from tensorflow.keras.applications import DenseNet121\n",
        "\n",
        "conv_base = DenseNet121(\n",
        "    weights='imagenet', \n",
        "    include_top=False, \n",
        "    input_shape=(32, 32, 3))\n",
        "\n",
        "conv_base.trainable = False"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nm1V79OGZ3I",
        "colab_type": "text"
      },
      "source": [
        "### Build and Compile the Pretrained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUjCa8qNGfFY",
        "colab_type": "text"
      },
      "source": [
        "Next, the model is built and compiled. This is very similar to creating the convolutional model from before, but the convolutional part is replaced by the pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNyRpUCCF9TD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "aeb9b20e-0ce6-4ae0-eac5-1a0d68697abf"
      },
      "source": [
        "pretrained_conv_model = tf.keras.models.Sequential(layers=(\n",
        "    conv_base,\n",
        "\n",
        "    tf.keras.layers.Dropout(0.1),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "))\n",
        "\n",
        "pretrained_conv_model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "densenet121 (Model)          (None, 1, 1, 1024)        7037504   \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 7,169,994\n",
            "Trainable params: 132,490\n",
            "Non-trainable params: 7,037,504\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44JEFuCWPoLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "pretrained_conv_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001), \n",
        "                              loss='categorical_crossentropy', \n",
        "                              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sW4X1Wh1PHDd",
        "colab_type": "text"
      },
      "source": [
        "### Train and Test the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXDYYc1JPaRW",
        "colab_type": "text"
      },
      "source": [
        "Next, the model is trained using the same parameters as the custom model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX-jauIqPe57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "faa5ece3-9e26-4e63-a586-622f37691c69"
      },
      "source": [
        "pretrained_conv_model.fit(cifar_train_images, \n",
        "                          cifar_train_labels, \n",
        "                          epochs=10, \n",
        "                          batch_size=32,\n",
        "                          validation_data=(cifar_validation_images, cifar_validation_labels))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1407/1407 [==============================] - 19s 14ms/step - loss: 1.2693 - accuracy: 0.5580 - val_loss: 1.1611 - val_accuracy: 0.5932\n",
            "Epoch 2/10\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0607 - accuracy: 0.6280 - val_loss: 1.1658 - val_accuracy: 0.6044\n",
            "Epoch 3/10\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9843 - accuracy: 0.6580 - val_loss: 1.0822 - val_accuracy: 0.6264\n",
            "Epoch 4/10\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9312 - accuracy: 0.6762 - val_loss: 1.1180 - val_accuracy: 0.6254\n",
            "Epoch 5/10\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8814 - accuracy: 0.6935 - val_loss: 1.1422 - val_accuracy: 0.6184\n",
            "Epoch 6/10\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8447 - accuracy: 0.7067 - val_loss: 1.1504 - val_accuracy: 0.6308\n",
            "Epoch 7/10\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.8092 - accuracy: 0.7195 - val_loss: 1.1682 - val_accuracy: 0.6266\n",
            "Epoch 8/10\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.7741 - accuracy: 0.7332 - val_loss: 1.2262 - val_accuracy: 0.6164\n",
            "Epoch 9/10\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.7387 - accuracy: 0.7447 - val_loss: 1.2863 - val_accuracy: 0.6152\n",
            "Epoch 10/10\n",
            "1407/1407 [==============================] - 17s 12ms/step - loss: 0.7135 - accuracy: 0.7546 - val_loss: 1.3410 - val_accuracy: 0.6136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f76ba4e1240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nss6pLkGRBE3",
        "colab_type": "text"
      },
      "source": [
        "The model is evaluated. It seems to perform about the same on the test data as the custom convolutional network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59NnlwdvQ7jt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "83b48695-1a63-4849-a911-af2e30e4bdfa"
      },
      "source": [
        "conv_model.evaluate(cifar_test_images, cifar_test_labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 1.2115 - accuracy: 0.6500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.211479663848877, 0.6499999761581421]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGpR5PUEQU65",
        "colab_type": "text"
      },
      "source": [
        "### Fine-tuning the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8OZCRoUQXJR",
        "colab_type": "text"
      },
      "source": [
        "The pretrained models can also be fine-tuned by allowing only some of the layers to be changed. The code below unfreezes the layer `conv5_block1_0_bn`, and all following layers so they can be updated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_452BZRFQj0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'conv5_block1_0_bn':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5fCseDUQqaP",
        "colab_type": "text"
      },
      "source": [
        "Next, the model is re-compiled and re-trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgymSzFHQwTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "pretrained_conv_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001), \n",
        "                              loss='categorical_crossentropy', \n",
        "                              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABl5IEThQ1dD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b88e6bec-da47-4fc2-b896-53255de67587"
      },
      "source": [
        "pretrained_conv_model.fit(cifar_train_images, \n",
        "                          cifar_train_labels, \n",
        "                          epochs=10, \n",
        "                          batch_size=32,\n",
        "                          validation_data=(cifar_validation_images, cifar_validation_labels))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1407/1407 [==============================] - 39s 27ms/step - loss: 1.4995 - accuracy: 0.5555 - val_loss: 1.2154 - val_accuracy: 0.6344\n",
            "Epoch 2/10\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 1.0542 - accuracy: 0.6432 - val_loss: 1.3805 - val_accuracy: 0.6492\n",
            "Epoch 3/10\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.9811 - accuracy: 0.6697 - val_loss: 2.0471 - val_accuracy: 0.6466\n",
            "Epoch 4/10\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.9062 - accuracy: 0.6898 - val_loss: 5.4409 - val_accuracy: 0.6376\n",
            "Epoch 5/10\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.8562 - accuracy: 0.7086 - val_loss: 7.7751 - val_accuracy: 0.6606\n",
            "Epoch 6/10\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.8243 - accuracy: 0.7234 - val_loss: 2.1375 - val_accuracy: 0.6828\n",
            "Epoch 7/10\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.7746 - accuracy: 0.7376 - val_loss: 5.3192 - val_accuracy: 0.6836\n",
            "Epoch 8/10\n",
            "1407/1407 [==============================] - 37s 26ms/step - loss: 0.7408 - accuracy: 0.7485 - val_loss: 8.3029 - val_accuracy: 0.6856\n",
            "Epoch 9/10\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 0.7025 - accuracy: 0.7637 - val_loss: 10.4070 - val_accuracy: 0.6808\n",
            "Epoch 10/10\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 0.6748 - accuracy: 0.7712 - val_loss: 13.5124 - val_accuracy: 0.6886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7694117da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EcXkmLwQ6b4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c0f52ad7-ef5e-4e25-ac18-e4de1b80c979"
      },
      "source": [
        "conv_model.evaluate(cifar_test_images, cifar_test_labels)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 1.2115 - accuracy: 0.6500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.211479663848877, 0.6499999761581421]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DaVaQvAVKUt",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7_SCwu3VPyk",
        "colab_type": "text"
      },
      "source": [
        "I have learned a lot about machine learning and Artificial Intelligence throughout this course. I have gained insight into the algorithms and processes that are used to generate neural networks and perform predictions on data, as well as the process for creating these networks. The information I have learned will be useful to me in the future, should I ever need to create a neural network for machine learning in my career."
      ]
    }
  ]
}